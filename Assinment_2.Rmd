
---
title: "Assignment-2"
author: "Eric Ohemeng"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document:
    df_print: paged
Github: github.com/Erico250/Assignment2
---

You may work in pairs or individually for this assignment. Make sure you join a group in Canvas if you are working in pairs. Turn in this assignment as an HTML or PDF file to ELMS. Make sure to include the R Markdown or Quarto file that was used to generate it.

```{r}
#| message = FALSE
library(tidyverse)
library(gtrendsR)
library(censusapi)
```

In this assignment, you will pull from APIs to get data from various data sources and use your data wrangling skills to use them all together. You should turn in a report in PDF or HTML format that addresses all of the questions in this assignment, and describes the data that you pulled and analyzed. You do not need to include full introduction and conclusion sections like a full report, but you should make sure to answer the questions in paragraph form, and include all relevant tables and graphics.

Whenever possible, use piping and `dplyr`. Avoid hard-coding any numbers within the report as much as possible.

## Pulling from APIs

Our first data source is the Google Trends API. Suppose we are interested in the search trends for `crime` and `loans` in Illinois in the year 2020. We could find this using the following code:

```{r}
res <- gtrends(c("crime", "loans"), 
               geo = "US-IL", 
               time = "2020-01-01 2020-12-31", 
               low_search_volume = TRUE)
plot(res)
```

Answer the following questions for the keywords "crime" and "loans".

-   Find the mean, median and variance of the search hits for the keywords.
```{r}
hits_data<- res$interest_over_time
summary(hits_data$hits[hits_data$keyword=="crime"])
summary(hits_data$hits[hits_data$keyword=="loans"])
```  

```{r}
var(hits_data$hits[hits_data$keyword=="crime"])
var(hits_data$hits[hits_data$keyword=="loans"])
```
*  Per the output above, the mean and median for "crime" keyword is 55 and 54 respectively. that of the "loans" is 66.62 and 66.5. The variance for the two keywords;crime and loans are 73 and 101 respectively. 

Which cities (locations) have the highest search frequency for `loans`? Note that there might be multiple rows for each city if there were hits for both "crime" and "loans" in that city. It might be easier to answer this question if we had the search hits info for both search terms in two separate variables. That is, each row would represent a unique city.

```{r}

res$interest_by_city

#rename dataframe interest by city to res_citydata:image/png;base64
res_city <- res$interest_by_city

# words into 2 variables, one for crime and one for loans

res_city_w  <- pivot_wider(res_city,
                          names_from = keyword, 
                          values_from = hits)
head(res_city_w)

sort(res_city_w$loans)
res_city_w$location[res_city_w$loans >=65]
```
* The cities with the highest search frequency for loans are Justice, Long Lake, Hurst, Rosemont and Alorton. 

Is there a relationship between the search intensities between the two keywords we used?

```{r}
res_city_w[is.na(res_city_w)] <- 0
cor(res_city_w$crime,res_city_w$loans)
```
* There is a weak negative relationship between crime and loans. 

Repeat the above for keywords related to covid. Make sure you use multiple keywords like we did above. Try several different combinations and think carefully about words that might make sense within this context.

```{r}
res2 <- gtrends(c("mask", "quarantine"), 
               geo = "US-IL", 
               time = "2020-01-01 2020-12-31", 
               low_search_volume = TRUE)
plot(res2)
```

- Find the mean, median and variance of the search hits for the keywords
```{r}

hits_data2<- res2$interest_over_time
hits_data2$hits <- as.numeric(hits_data2$hits)
summary(hits_data2$hits[hits_data2$keyword=="mask"])
summary(hits_data2$hits[hits_data2$keyword=="quarantine"])
```
*  

```{r}
var(hits_data2$hits[hits_data2$keyword=="mask"])
var(hits_data2$hits[hits_data2$keyword=="quarantine"], na.rm = TRUE)
```
*The mean and median of keyword "mask"is 37.37 and 31 respectively while that of the "quarantine" is 10 and 8. The variance for the two keywords;mask and quarantine are 509 and 66 respectively

```{r}
res2$interest_by_city

#rename dataframe interest by city to res_citydata:image/png;base64
res_city2 <- res2$interest_by_city

# words into 2 variables, one for crime and one for loans

res_city_w2  <- pivot_wider(res_city2,
                          names_from = keyword, 
                          values_from = hits)
head(res_city_w2)

sort(res_city_w2$mask)
res_city_w2$location[res_city_w2$mask >= 84]

```

* the cities with the highest search frequencies for mask are Toluca,Mount Pulaski and Benld. 
```{r}
res_city_w2[is.na(res_city_w2)] <- 0
cor(res_city_w2$mask, res_city_w2$quarantine)
```
* The correlation coefficient indicates that there is a weak negative relationship be tween mask and quarantine.

## Google Trends + ACS

Now lets add another data set. The `censusapi` package provides a nice R interface for communicating with this API. However, before running queries we need an access key. This (easy) process can be completed here:

<https://api.census.gov/data/key_signup.html>

Once you have an access key, store this key in the `cs_key` object. We will use this object in all following API queries.

```{r}
#| eval: false
cs_key <- "0ec6746be66ce182d2af1c288b709ff5cb9758ee"
```

In the following, we request basic socio-demographic information (population, median age, median household income, income per capita) for cities and villages in the state of Illinois.

```{r}
#| eval: false

acs_il <- getCensus(name = "acs/acs5",
                    vintage = 2020, 
                    vars = c("NAME", 
                             "B01001_001E", 
                             "B06002_001E", 
                             "B19013_001E", 
                             "B19301_001E"), 
                    region = "place:*", 
                    regionin = "state:17",
                    key = cs_key)
head(acs_il)
```

Convert values that represent missings to NAs.

```{r}
#| eval: false

acs_il[acs_il == -666666666] <- NA
```

Now, it might be useful to rename the socio-demographic variables (`B01001_001E` etc.) in our data set and assign more meaningful names.

```{r}
#| eval: false
acs_il <- acs_il %>%
  rename(pop = B01001_001E, 
         age = B06002_001E, 
         hh_income = B19013_001E, 
         income = B19301_001E)
```

It seems like we could try to use this location information listed above to merge this data set with the Google Trends data. However, we first have to clean `NAME` so that it has the same structure as `location` in the search interest by city data. Add a new variable `location` to the ACS data that only includes city names.

Answer the following questions with the "crime" and "loans" Google trends data and the ACS data.

-   First, check how many cities don't appear in both data sets, i.e. cannot be matched. Then, create a new data set by joining the Google Trends and the ACS data. Keep only cities that appear in both data sets.

-   Compute the mean of the search popularity for both keywords for cities that have an above average median household income and for those that have an below average median household income. When building your pipe, start with creating the grouping variable and then proceed with the remaining tasks. What conclusions might you draw from this?

-   Is there a relationship between the median household income and the search popularity of the Google trends terms? Describe the relationship and use a scatterplot with `qplot()`.

Repeat the above steps using the covid data and the ACS data.

```{r}

# create a 'location' variable with only city names
acs_il <- acs_il %>%
  mutate(location = sub(",.*$", "", NAME))

# Removing city
acs_il$location <- gsub(" city","",acs_il$location) 

# Removing village
acs_il$location <- gsub(" village","",acs_il$location)

# Removing CDP
acs_il$location <- gsub(" CDP","",acs_il$location)

# Check how many cities don't appear in both data sets
missing_cities <- anti_join(acs_il, res_city_w, by = "location")
nrow(missing_cities)

# Create a new dataset by joining the Google Trends and ACS data for matching cities
common <- intersect(res_city_w$location,acs_il$location)

merged_data <- inner_join(res_city_w, acs_il, by = "location")
nrow(merged_data)

# Compute the mean search popularity for "crime" and "loans" for above and below average median household income
merged_data <- merged_data %>% 
  mutate(income_diff= ifelse(hh_income>mean(hh_income,na.rm=TRUE), 1, 0))



head(merged_data)

```


```{r}
merged_data %>%
  group_by(income_diff) %>%
  summarise(mean_search_crime = mean(crime),
            mean_search_loans = mean(loans))

```
* under the income_diff columm, cities that have above anerage household income is coded as 1, and those below is coded as 0. The mean of crime search  for cities that have an above average median household income is 11.77 while those below is 6.11. The mean search for loans for cities that have an above average median household income is 12.56 and for those that have an below average median household income is 14.67 



